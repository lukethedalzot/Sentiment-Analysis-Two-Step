{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries used and initial data retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\dalzo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dalzo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('punkt') #gives error if not specified!\n",
    "import numpy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "def lol2str(doc):\n",
    "    return \" \".join([w for sent in doc for w in sent])\n",
    "\n",
    "mr = movie_reviews\n",
    "neg = mr.paras(categories='neg')\n",
    "pos = mr.paras(categories='pos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "tv = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bias = MultinomialNB()\n",
    "lsvm = SVC(kernel=\"linear\", C=0.025)\n",
    "svm = SVC()\n",
    "dl = MLPClassifier(alpha=1, max_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 scores before the objectivity removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE-REMOVAL \n",
      " CountVectorizer\n",
      "Naive Bayes Classifier:  0.814\n",
      "Linear SVM:  0.835\n",
      "SVM:  0.764\n",
      "Neural Net:  0.839\n",
      "\n",
      " TfidfVectorizer\n",
      "Naive Bayes Classifier:  0.808\n",
      "Linear SVM:  0.752\n",
      "SVM:  0.841\n",
      "Neural Net:  0.846\n"
     ]
    }
   ],
   "source": [
    "print('PRE-REMOVAL','\\n','CountVectorizer')\n",
    "corpus = [lol2str(d) for d in neg] + [lol2str(d) for d in pos]\n",
    "labels_pre = numpy.array([0] * len(neg) + [1] * len(pos))\n",
    "vectors_pre = cv.fit_transform(corpus)\n",
    "\n",
    "scores = cross_validate(naive_bias, vectors_pre, labels_pre, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Naive Bayes Classifier: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(lsvm, vectors_pre, labels_pre, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Linear SVM: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(svm, vectors_pre, labels_pre, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"SVM: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(dl, vectors_pre, labels_pre, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Neural Net: \",round(average, 3))\n",
    "\n",
    "\n",
    "print('\\n', 'TfidfVectorizer')\n",
    "vectors_pre = tv.fit_transform(corpus)\n",
    "\n",
    "scores = cross_validate(naive_bias, vectors_pre, labels_pre, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Naive Bayes Classifier: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(lsvm, vectors_pre, labels_pre, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Linear SVM: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(svm, vectors_pre, labels_pre, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"SVM: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(dl, vectors_pre, labels_pre, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Neural Net: \",round(average, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function used to remove the objectivity from sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeObjectivity(corpus, level= 0.4):\n",
    "    \"\"\"\n",
    "    corpus = the dataset that should be a list of reviews where for each review \n",
    "    there are list of sentences and fpr the sentences a list of words \n",
    "    level = how much objectivity do we want to remove? \n",
    "    (0 totaly objective 1 totally subjective) 0.4 as default\n",
    "    \"\"\"\n",
    "    updated_corpus = []\n",
    "    removed_sentences = 0\n",
    "    s = 0\n",
    "    sent= \"\"\n",
    "    for review in corpus:\n",
    "        updated_sentences=[]\n",
    "        for sentence in review:\n",
    "            for word in sentence:\n",
    "                sent += word + \" \"\n",
    "            txtblob = TextBlob(sent)\n",
    "            s += 1\n",
    "            if (txtblob.sentiment[1] > level):\n",
    "                updated_sentences.append(sent)\n",
    "            else:\n",
    "                removed_sentences += 1\n",
    "            sent = \"\"\n",
    "        if (len(updated_sentences) > 0):\n",
    "            upd_review = \"\"\n",
    "            for sents in updated_sentences:\n",
    "                upd_review += sents\n",
    "                #upd_review += \" \"\n",
    "            updated_corpus.append(upd_review)\n",
    "    return updated_corpus, removed_sentences, s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing what changes after the objectivity is removed. Note that changing the i variable too high could lead to a mismatch between the reviews before and after the removal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything in the phantom you have seen many times before and there is nothing new presented here . wincer displays absolutely no skill in setting up an exciting action sequence . billy zane is wooden as the hero . kristy swanson is given very little to do , and does very little with it . treat williams , looking like rhett butler but sounding like mickey mouse , is one of the worst villains i have ever seen in a movie . only catherine zeta jones , as one of williams cohorts turns in a good performance . she has energy and spunk , which the movie needed much more of . oh yeah , the phantom also has a secret identity but this is so poorly played out you won ' t even care . about the only things i can recommend are a good performance by jones , and some colorful scenery . however , if youre looking for a fun family movie , go watch the underrated flipper . this is not a good movie . \n",
      "\n",
      "Sentences to remove with a threshold of  0.3 :\n",
      "billy zane is wooden as the hero . -> 0.0\n",
      "however , if youre looking for a fun family movie , go watch the underrated flipper . -> 0.2\n",
      "everything in the phantom you have seen many times before and there is nothing new presented here . wincer displays absolutely no skill in setting up an exciting action sequence . kristy swanson is given very little to do , and does very little with it . treat williams , looking like rhett butler but sounding like mickey mouse , is one of the worst villains i have ever seen in a movie . only catherine zeta jones , as one of williams cohorts turns in a good performance . she has energy and spunk , which the movie needed much more of . oh yeah , the phantom also has a secret identity but this is so poorly played out you won ' t even care . about the only things i can recommend are a good performance by jones , and some colorful scenery . this is not a good movie . \n"
     ]
    }
   ],
   "source": [
    "flat_neg = [lol2str(d) for d in neg]\n",
    "print(flat_neg[875],'\\n') \n",
    "i = 0.3\n",
    "print('Sentences to remove with a threshold of ',i,':')\n",
    "review = TextBlob(flat_neg[875])\n",
    "for sent in review.sentences:\n",
    "    if sent.sentiment[1]<i:\n",
    "        print(str(sent), '->', sent.sentiment[1])\n",
    "new_neg, n, k = removeObjectivity(neg,i)\n",
    "print(new_neg[875])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 scores and for threshold=0.4 with all combinations of classifiers and vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences:  71532\n",
      "Removed sentences:  35035\n",
      "POST-RIMOZIONE \n",
      " CountVectorizer\n",
      "Naive Bayes Classifier:  0.824\n",
      "Linear SVM:  0.826\n",
      "SVM:  0.771\n",
      "Neural Net:  0.832\n",
      "\n",
      " TfidfVectorizer\n",
      "Naive Bayes Classifier:  0.834\n",
      "Linear SVM:  0.778\n",
      "SVM:  0.855\n",
      "Neural Net:  0.853\n"
     ]
    }
   ],
   "source": [
    "new_corpus_neg, removed_neg, sent_neg = removeObjectivity(neg, 0.4)\n",
    "new_corpus_pos, removed_pos, sent_pos = removeObjectivity(pos, 0.4)\n",
    "new_corpus = new_corpus_neg+new_corpus_pos\n",
    "\n",
    "removed = removed_neg + removed_pos \n",
    "sent = sent_neg +  sent_pos\n",
    "print(\"Total sentences: \", sent)\n",
    "print(\"Removed sentences: \", removed)\n",
    "\n",
    "labels_post = numpy.array([0] * len(new_corpus_neg) + [1] * len(new_corpus_pos))\n",
    "\n",
    "print('POST-REMOVAL','\\n','CountVectorizer')\n",
    "\n",
    "vectors_post = cv.fit_transform(new_corpus)\n",
    "\n",
    "scores = cross_validate(naive_bias, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Naive Bayes Classifier: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(lsvm, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Linear SVM: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(svm, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"SVM: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(dl, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Neural Net: \",round(average, 3))\n",
    "\n",
    "print('\\n', 'TfidfVectorizer')\n",
    "vectors_post = tv.fit_transform(new_corpus)\n",
    "\n",
    "scores = cross_validate(naive_bias, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Naive Bayes Classifier: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(lsvm, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Linear SVM: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(svm, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"SVM: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(dl, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Neural Net: \",round(average, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences:  71532\n",
      "Removed sentences:  27413\n",
      "POST-RIMOZIONE \n",
      " CountVectorizer\n",
      "Naive Bayes Classifier:  0.823\n",
      "Linear SVM:  0.82\n",
      "SVM:  0.768\n",
      "Neural Net:  0.828\n",
      "\n",
      " TfidfVectorizer\n",
      "Naive Bayes Classifier:  0.833\n",
      "Linear SVM:  0.782\n",
      "SVM:  0.844\n",
      "Neural Net:  0.861\n"
     ]
    }
   ],
   "source": [
    "new_corpus_neg, removed_neg, sent_neg = removeObjectivity(neg, 0.3)\n",
    "new_corpus_pos, removed_pos, sent_pos = removeObjectivity(pos, 0.3)\n",
    "new_corpus = new_corpus_neg+new_corpus_pos\n",
    "\n",
    "removed = removed_neg + removed_pos \n",
    "sent = sent_neg +  sent_pos\n",
    "print(\"Total sentences: \", sent)\n",
    "print(\"Removed sentences: \", removed)\n",
    "\n",
    "labels_post = numpy.array([0] * len(new_corpus_neg) + [1] * len(new_corpus_pos))\n",
    "\n",
    "print('POST-RIMOZIONE','\\n','CountVectorizer')\n",
    "\n",
    "vectors_post = cv.fit_transform(new_corpus)\n",
    "\n",
    "scores = cross_validate(naive_bias, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Naive Bayes Classifier: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(lsvm, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Linear SVM: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(svm, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"SVM: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(dl, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Neural Net: \",round(average, 3))\n",
    "\n",
    "print('\\n', 'TfidfVectorizer')\n",
    "vectors_post = tv.fit_transform(new_corpus)\n",
    "\n",
    "scores = cross_validate(naive_bias, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Naive Bayes Classifier: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(lsvm, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Linear SVM: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(svm, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"SVM: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(dl, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Neural Net: \",round(average, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
