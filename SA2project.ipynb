{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries used and initial data retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\dalzo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dalzo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('punkt') #gives error if not specified!\n",
    "import numpy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from textblob import TextBlob\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "\n",
    "\n",
    "\n",
    "def lol2str(doc):\n",
    "    return \" \".join([w for sent in doc for w in sent])\n",
    "\n",
    "mr = movie_reviews\n",
    "neg = mr.paras(categories='neg')\n",
    "pos = mr.paras(categories='pos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "tv = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bias = MultinomialNB()\n",
    "lsvm = SVC(kernel=\"linear\", C=0.025)\n",
    "svm = SVC()\n",
    "dl = MLPClassifier(alpha=1, max_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 scores before the objectivity removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE-REMOVAL \n",
      " CountVectorizer\n",
      "Naive Bayes Classifier:  0.814\n",
      "Linear SVM:  0.835\n",
      "SVM:  0.764\n",
      "Neural Net:  0.839\n",
      "\n",
      " TfidfVectorizer\n",
      "Naive Bayes Classifier:  0.808\n",
      "Linear SVM:  0.752\n",
      "SVM:  0.841\n",
      "Neural Net:  0.846\n"
     ]
    }
   ],
   "source": [
    "print('PRE-REMOVAL','\\n','CountVectorizer')\n",
    "corpus = [lol2str(d) for d in neg] + [lol2str(d) for d in pos]\n",
    "labels_pre = numpy.array([0] * len(neg) + [1] * len(pos))\n",
    "vectors_pre = cv.fit_transform(corpus)\n",
    "\n",
    "scores = cross_validate(naive_bias, vectors_pre, labels_pre, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Naive Bayes Classifier: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(lsvm, vectors_pre, labels_pre, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Linear SVM: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(svm, vectors_pre, labels_pre, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"SVM: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(dl, vectors_pre, labels_pre, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Neural Net: \",round(average, 3))\n",
    "\n",
    "\n",
    "print('\\n', 'TfidfVectorizer')\n",
    "vectors_pre = tv.fit_transform(corpus)\n",
    "\n",
    "scores = cross_validate(naive_bias, vectors_pre, labels_pre, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Naive Bayes Classifier: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(lsvm, vectors_pre, labels_pre, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Linear SVM: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(svm, vectors_pre, labels_pre, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"SVM: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(dl, vectors_pre, labels_pre, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Neural Net: \",round(average, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function used to remove the objectivity from sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeObjectivity(corpus, level= 0.4):\n",
    "    \"\"\"\n",
    "    corpus = the dataset that should be a list of reviews where for each review \n",
    "    there are list of sentences and fpr the sentences a list of words \n",
    "    level = how much objectivity do we want to remove? \n",
    "    (0 totaly objective 1 totally subjective) 0.4 as default\n",
    "    \"\"\"\n",
    "    updated_corpus = []\n",
    "    removed_sentences = 0\n",
    "    s = 0\n",
    "    sent= \"\"\n",
    "    for review in corpus:\n",
    "        updated_sentences=[]\n",
    "        for sentence in review:\n",
    "            for word in sentence:\n",
    "                sent += word + \" \"\n",
    "            txtblob = TextBlob(sent)\n",
    "            s += 1\n",
    "            if (txtblob.sentiment[1] > level):\n",
    "                updated_sentences.append(sent)\n",
    "            else:\n",
    "                removed_sentences += 1\n",
    "            sent = \"\"\n",
    "        if (len(updated_sentences) > 0):\n",
    "            upd_review = \"\"\n",
    "            for sents in updated_sentences:\n",
    "                upd_review += sents\n",
    "            updated_corpus.append(upd_review)\n",
    "    return updated_corpus, removed_sentences, s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing what changes after the objectivity is removed. Note that changing the i variable too high could lead to a mismatch between the reviews before and after the removal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything in the phantom you have seen many times before and there is nothing new presented here . wincer displays absolutely no skill in setting up an exciting action sequence . billy zane is wooden as the hero . kristy swanson is given very little to do , and does very little with it . treat williams , looking like rhett butler but sounding like mickey mouse , is one of the worst villains i have ever seen in a movie . only catherine zeta jones , as one of williams cohorts turns in a good performance . she has energy and spunk , which the movie needed much more of . oh yeah , the phantom also has a secret identity but this is so poorly played out you won ' t even care . about the only things i can recommend are a good performance by jones , and some colorful scenery . however , if youre looking for a fun family movie , go watch the underrated flipper . this is not a good movie . \n",
      "\n",
      "Sentences to remove with a threshold of  0.3 :\n",
      "billy zane is wooden as the hero . -> 0.0\n",
      "however , if youre looking for a fun family movie , go watch the underrated flipper . -> 0.2\n",
      "everything in the phantom you have seen many times before and there is nothing new presented here . wincer displays absolutely no skill in setting up an exciting action sequence . kristy swanson is given very little to do , and does very little with it . treat williams , looking like rhett butler but sounding like mickey mouse , is one of the worst villains i have ever seen in a movie . only catherine zeta jones , as one of williams cohorts turns in a good performance . she has energy and spunk , which the movie needed much more of . oh yeah , the phantom also has a secret identity but this is so poorly played out you won ' t even care . about the only things i can recommend are a good performance by jones , and some colorful scenery . this is not a good movie . \n"
     ]
    }
   ],
   "source": [
    "flat_neg = [lol2str(d) for d in neg]\n",
    "print(flat_neg[875],'\\n') \n",
    "i = 0.3\n",
    "print('Sentences to remove with a threshold of ',i,':')\n",
    "review = TextBlob(flat_neg[875])\n",
    "for sent in review.sentences:\n",
    "    if sent.sentiment[1]<i:\n",
    "        print(str(sent), '->', sent.sentiment[1])\n",
    "new_neg, n, k = removeObjectivity(neg,i)\n",
    "print(new_neg[875])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 scores and for threshold=0.4 with all combinations of classifiers and vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences:  71532\n",
      "Removed sentences:  35035\n",
      "POST-RIMOZIONE \n",
      " CountVectorizer\n",
      "Naive Bayes Classifier:  0.824\n",
      "Linear SVM:  0.826\n",
      "SVM:  0.771\n",
      "Neural Net:  0.832\n",
      "\n",
      " TfidfVectorizer\n",
      "Naive Bayes Classifier:  0.834\n",
      "Linear SVM:  0.778\n",
      "SVM:  0.855\n",
      "Neural Net:  0.853\n"
     ]
    }
   ],
   "source": [
    "new_corpus_neg, removed_neg, sent_neg = removeObjectivity(neg, 0.4)\n",
    "new_corpus_pos, removed_pos, sent_pos = removeObjectivity(pos, 0.4)\n",
    "new_corpus = new_corpus_neg+new_corpus_pos\n",
    "\n",
    "removed = removed_neg + removed_pos \n",
    "sent = sent_neg +  sent_pos\n",
    "print(\"Total sentences: \", sent)\n",
    "print(\"Removed sentences: \", removed)\n",
    "\n",
    "labels_post = numpy.array([0] * len(new_corpus_neg) + [1] * len(new_corpus_pos))\n",
    "\n",
    "print('POST-REMOVAL','\\n','CountVectorizer')\n",
    "\n",
    "vectors_post = cv.fit_transform(new_corpus)\n",
    "\n",
    "scores = cross_validate(naive_bias, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Naive Bayes Classifier: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(lsvm, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Linear SVM: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(svm, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"SVM: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(dl, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Neural Net: \",round(average, 3))\n",
    "\n",
    "print('\\n', 'TfidfVectorizer')\n",
    "vectors_post = tv.fit_transform(new_corpus)\n",
    "\n",
    "scores = cross_validate(naive_bias, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Naive Bayes Classifier: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(lsvm, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Linear SVM: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(svm, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"SVM: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(dl, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Neural Net: \",round(average, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 scores and for threshold=0.3 with all combinations of classifiers and vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences:  71532\n",
      "Removed sentences:  27413\n",
      "POST-RIMOZIONE \n",
      " CountVectorizer\n",
      "Naive Bayes Classifier:  0.823\n",
      "Linear SVM:  0.82\n",
      "SVM:  0.768\n",
      "Neural Net:  0.828\n",
      "\n",
      " TfidfVectorizer\n",
      "Naive Bayes Classifier:  0.833\n",
      "Linear SVM:  0.782\n",
      "SVM:  0.844\n",
      "Neural Net:  0.861\n"
     ]
    }
   ],
   "source": [
    "new_corpus_neg, removed_neg, sent_neg = removeObjectivity(neg, 0.3)\n",
    "new_corpus_pos, removed_pos, sent_pos = removeObjectivity(pos, 0.3)\n",
    "new_corpus = new_corpus_neg+new_corpus_pos\n",
    "\n",
    "removed = removed_neg + removed_pos \n",
    "sent = sent_neg +  sent_pos\n",
    "print(\"Total sentences: \", sent)\n",
    "print(\"Removed sentences: \", removed)\n",
    "\n",
    "labels_post = numpy.array([0] * len(new_corpus_neg) + [1] * len(new_corpus_pos))\n",
    "\n",
    "print('POST-RIMOZIONE','\\n','CountVectorizer')\n",
    "\n",
    "vectors_post = cv.fit_transform(new_corpus)\n",
    "\n",
    "scores = cross_validate(naive_bias, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Naive Bayes Classifier: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(lsvm, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Linear SVM: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(svm, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"SVM: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(dl, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Neural Net: \",round(average, 3))\n",
    "\n",
    "print('\\n', 'TfidfVectorizer')\n",
    "vectors_post = tv.fit_transform(new_corpus)\n",
    "\n",
    "scores = cross_validate(naive_bias, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Naive Bayes Classifier: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(lsvm, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Linear SVM: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(svm, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"SVM: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(dl, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Neural Net: \",round(average, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Textblob to do the sentiment evaluation   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing the objective sentences 0.802\n"
     ]
    }
   ],
   "source": [
    "negative_reviews = [lol2str(d) for d in neg]\n",
    "positive_reviews = [lol2str(d) for d in pos]\n",
    "reviews = negative_reviews + positive_reviews\n",
    "labels = numpy.array([0] * len(negative_reviews) + [1] * len(positive_reviews))\n",
    "\n",
    "reviews_train, reviews_test, y_train, y_test = train_test_split(\n",
    "    reviews, labels, test_size=0.25, random_state=8)\n",
    "\n",
    "test = []\n",
    "train = []\n",
    "\n",
    "for i, review in enumerate(reviews_train):\n",
    "    if(y_train[i] == 0):\n",
    "        train.append((review, 'neg'))\n",
    "    else:\n",
    "        train.append((review, 'pos'))\n",
    "\n",
    "for i, review in enumerate(reviews_test):\n",
    "    if(y_test[i] == 0):\n",
    "        test.append((review, 'neg'))\n",
    "    else:\n",
    "        test.append((review, 'pos'))\n",
    "\n",
    "cl = NaiveBayesClassifier(train)\n",
    "print(\"Before removing the objective sentences\",cl.accuracy(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After objectivity removal\n",
      "0.796\n"
     ]
    }
   ],
   "source": [
    "new_corpus_neg, removed_neg, sent_neg = removeObjectivity(neg, 0.3)\n",
    "new_corpus_pos, removed_pos, sent_pos = removeObjectivity(pos, 0.3)\n",
    "new_reviews = new_corpus_neg + new_corpus_pos\n",
    "labels = numpy.array([0] * len(new_corpus_neg) + [1] * len(new_corpus_pos))\n",
    "\n",
    "reviews_train, reviews_test, y_train, y_test = train_test_split(\n",
    "    new_reviews, labels, test_size=0.25, random_state=8)\n",
    "\n",
    "new_test = []\n",
    "new_train = []\n",
    "\n",
    "for i, review in enumerate(reviews_train):\n",
    "    if(y_train[i] == 0):\n",
    "        new_train.append((review, 'neg'))\n",
    "    else:\n",
    "        new_train.append((review, 'pos'))\n",
    "\n",
    "for i, review in enumerate(reviews_test):\n",
    "    if(y_test[i] == 0):\n",
    "        new_test.append((review, 'neg'))\n",
    "    else:\n",
    "        new_test.append((review, 'pos'))\n",
    "\n",
    "print(\"After objectivity removal\")\n",
    "new_cl = NaiveBayesClassifier(new_train)\n",
    "print(new_cl.accuracy(new_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These next few sections are for the training of a model for subjectivity detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file1 = open('Subjectivity Dataset/objective.txt', 'r')\n",
    "Lines = file1.readlines()\n",
    "obj = []\n",
    "for line in Lines:\n",
    "    obj.append(line)\n",
    "file2 = open('Subjectivity Dataset/subjective.txt', 'r')\n",
    "Lines = file2.readlines()\n",
    "subj = []\n",
    "for line in Lines:\n",
    "    subj.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the model for subjectivity detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8972\n"
     ]
    }
   ],
   "source": [
    "sentences = obj + subj\n",
    "labels = numpy.array([0] * len(obj) + [1] * len(subj))\n",
    "sentences_train, sentences_test, y_train, y_test = train_test_split(\n",
    "    sentences, labels, test_size=0.25, random_state=8)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(sentences_train)\n",
    "\n",
    "X_train = vectorizer.transform(sentences_train)\n",
    "X_test  = vectorizer.transform(sentences_test)\n",
    "\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "score = classifier.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New method for removng objective sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newRemoveObjectivity(corpus, model, vectorizer):\n",
    "    \"\"\"\n",
    "    corpus = the dataset that should be a list of reviews where for each review \n",
    "    model = the already trained model to categorize a sentece being subjective or objective\n",
    "    vectorizer = this should be the same as the one used to train the previous model\n",
    "    \"\"\"\n",
    "    updated_corpus = []\n",
    "    removed_sentences = 0\n",
    "    s = 0\n",
    "    sent= \"\"\n",
    "    for review in corpus:\n",
    "        updated_sentences=[]\n",
    "        for sentence in review:\n",
    "            x = []\n",
    "            for word in sentence:\n",
    "                sent += word + \" \"\n",
    "            x.append(sent)\n",
    "            x = vectorizer.transform(x)\n",
    "            prediction = model.predict(x)\n",
    "            s += 1\n",
    "            if (prediction == [1]): #meaning that the sentence is considered subjective\n",
    "                updated_sentences.append(sent)\n",
    "            else:\n",
    "                removed_sentences += 1\n",
    "            sent = \"\"\n",
    "        if (len(updated_sentences) > 0):\n",
    "            upd_review = \"\"\n",
    "            for sents in updated_sentences:\n",
    "                upd_review += sents\n",
    "            updated_corpus.append(upd_review)\n",
    "    return updated_corpus, removed_sentences, s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the new dataset and computing number of removed sentences to compare with previous method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences:  71532\n",
      "Removed sentences:  25156\n"
     ]
    }
   ],
   "source": [
    "new_corpus_neg, removed_neg, sent_neg = newRemoveObjectivity(neg, classifier, vectorizer)\n",
    "new_corpus_pos, removed_pos, sent_pos = newRemoveObjectivity(pos, classifier, vectorizer)\n",
    "removed = removed_neg + removed_pos \n",
    "sent = sent_neg +  sent_pos\n",
    "print(\"Total sentences: \", sent)\n",
    "print(\"Removed sentences: \", removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the F1 scrores with different classifiers without using TextBlob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without using TextBlob\n",
      "TfidfVectorizer\n",
      "Naive Bayes Classifier:  0.833\n",
      "Linear SVM:  0.781\n",
      "SVM:  0.864\n",
      "Neural Net:  0.868\n"
     ]
    }
   ],
   "source": [
    "labels_post = numpy.array([0] * len(new_corpus_neg) + [1] * len(new_corpus_pos))\n",
    "new_corpus = new_corpus_neg+new_corpus_pos\n",
    "print('Without using TextBlob\\nTfidfVectorizer')\n",
    "vectors_post = tv.fit_transform(new_corpus)\n",
    "\n",
    "scores = cross_validate(naive_bias, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Naive Bayes Classifier: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(lsvm, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Linear SVM: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(svm, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"SVM: \",round(average, 3))\n",
    "\n",
    "scores = cross_validate(dl, vectors_post, labels_post, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(\"Neural Net: \",round(average, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
